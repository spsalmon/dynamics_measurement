{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from towbintools.foundation.image_handling import read_tiff_file\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage.util import img_as_ubyte\n",
    "import pandas as pd\n",
    "\n",
    "from skimage import (\n",
    "    data, restoration, util\n",
    ")\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import warnings\n",
    "from towbintools.foundation.file_handling import get_dir_filemap, add_dir_to_experiment_filemap\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_stack_nuclear_stats(\n",
    "    raw_stack,\n",
    "    mask_stack,\n",
    "    kernel=cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7)),\n",
    "):\n",
    "    nuclear_stats_df = pd.DataFrame()\n",
    "    for i, plane in enumerate(raw_stack):\n",
    "        raw = plane - np.median(plane)\n",
    "        nuclei_mask = (mask_stack[i] > 0).astype(int)\n",
    "        nuclei_labels = mask_stack[i]\n",
    "\n",
    "        unique_labels = np.unique(nuclei_labels)\n",
    "        # remove label 0\n",
    "        unique_labels = unique_labels[unique_labels > 0]\n",
    "\n",
    "        for lbl in unique_labels:\n",
    "            mask_of_label = (nuclei_labels == lbl).astype(int)\n",
    "            expanded_label = (\n",
    "                cv2.morphologyEx(img_as_ubyte(mask_of_label), cv2.MORPH_DILATE, kernel) > 0\n",
    "            ).astype(int)\n",
    "\n",
    "            cytoplasm_mask = (expanded_label - mask_of_label - nuclei_mask > 0).astype(int)\n",
    "\n",
    "            mean_intensity_cytoplasm = np.mean(raw[cytoplasm_mask == 1])\n",
    "            median_intensity_cytoplasm = np.median(raw[cytoplasm_mask == 1])\n",
    "\n",
    "            mean_intensity_nucleus = np.mean(raw[nuclei_mask == 1])\n",
    "            median_intensity_nucleus = np.median(raw[nuclei_mask == 1])\n",
    "\n",
    "            label_result_dict = {\n",
    "                    \"Plane\": i,\n",
    "                    \"Label\": lbl,\n",
    "                    \"MeanIntensityCytoplasm\": mean_intensity_cytoplasm,\n",
    "                    \"MedianIntensityCytoplasm\": median_intensity_cytoplasm,\n",
    "                    \"MeanIntensityNucleus\": mean_intensity_nucleus,\n",
    "                    \"MedianIntensityNucleus\": median_intensity_nucleus,\n",
    "                }\n",
    "            nuclear_stats_df = pd.concat([nuclear_stats_df, pd.DataFrame(label_result_dict, index=[0])])\n",
    "        \n",
    "    return nuclear_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing point 0\n",
      "Processing time 0\n",
      "Processing time 6\n",
      "Processing time 12\n",
      "Processing time 18\n",
      "Processing time 24\n",
      "Processing time 30\n",
      "Processing time 36\n",
      "Processing time 42\n",
      "Processing time 48\n",
      "Processing time 54\n",
      "Processing time 60\n",
      "Processing time 66\n",
      "Processing time 72\n",
      "Processing time 78\n",
      "Processing time 84\n",
      "Processing time 90\n",
      "Processing time 96\n",
      "Processing time 102\n",
      "Processing time 108\n",
      "Processing time 114\n",
      "Processing time 120\n",
      "Processing time 126\n",
      "Processing time 132\n",
      "Processing time 138\n",
      "Processing time 144\n",
      "Processing time 150\n",
      "Processing time 156\n",
      "Processing time 162\n",
      "Processing time 168\n",
      "Processing time 174\n",
      "Processing time 180\n",
      "Processing time 186\n",
      "Processing time 192\n",
      "Processing time 198\n",
      "Processing time 204\n"
     ]
    },
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing point \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m point_data \u001b[38;5;241m=\u001b[39m filemap[filemap[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPoint\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m point]\n\u001b[0;32m---> 59\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_time\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoint_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpoint_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/mainproject/lib/python3.9/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/micromamba/envs/mainproject/lib/python3.9/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "Cell \u001b[0;32mIn[9], line 47\u001b[0m, in \u001b[0;36mprocess_time\u001b[0;34m(time, point_data)\u001b[0m\n\u001b[1;32m     45\u001b[0m raw_stack \u001b[38;5;241m=\u001b[39m read_tiff_file(raw_path, channels_to_keep \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     46\u001b[0m mask_stack \u001b[38;5;241m=\u001b[39m read_tiff_file(mask_path)\n\u001b[0;32m---> 47\u001b[0m classification_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassification_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m nuclei_stats_df \u001b[38;5;241m=\u001b[39m measure_stack_nuclear_stats(raw_stack, mask_stack)\n\u001b[1;32m     50\u001b[0m nuclei_stats_df \u001b[38;5;241m=\u001b[39m nuclei_stats_df\u001b[38;5;241m.\u001b[39mmerge(classification_df, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlane\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m], how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/micromamba/envs/mainproject/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1012\u001b[0m     dialect,\n\u001b[1;32m   1013\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/mainproject/lib/python3.9/site-packages/pandas/io/parsers/readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/micromamba/envs/mainproject/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/mainproject/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1896\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1893\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1895\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1898\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/mainproject/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32mparsers.pyx:581\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "img_dir = '/mnt/towbin.data/shared/spsalmon/20240524_161257_273_LIPSI_40x_397_405_no_crash/raw_ometiff/pad1/'\n",
    "mask_dir = '/mnt/towbin.data/shared/spsalmon/20240524_161257_273_LIPSI_40x_397_405_no_crash/analysis/ch1_seg_stardist/pad1/'\n",
    "classification_dir = '/mnt/towbin.data/shared/spsalmon/20240524_161257_273_LIPSI_40x_397_405_no_crash/analysis/nuclei_types/pad1/'\n",
    "\n",
    "filemap = get_dir_filemap(img_dir)\n",
    "filemap = add_dir_to_experiment_filemap(filemap, mask_dir, \"MaskPath\")\n",
    "filemap = add_dir_to_experiment_filemap(filemap, classification_dir, \"ClassificationPath\")\n",
    "\n",
    "output_dir = '/mnt/towbin.data/shared/spsalmon/20240524_161257_273_LIPSI_40x_397_405_no_crash/analysis/nuclei_stats/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# keep only rows with mask and classification\n",
    "filemap = filemap[filemap['MaskPath'] != '']\n",
    "filemap = filemap[filemap['ClassificationPath'] != '']\n",
    "\n",
    "# for point in filemap['Point'].unique():\n",
    "#     print(f\"Processing point {point}\")\n",
    "#     point_data = filemap[filemap['Point'] == point]\n",
    "\n",
    "#     for time in point_data['Time'].unique():\n",
    "#         print(f\"Processing time {time}\")\n",
    "#         time_data = point_data[point_data['Time'] == time]\n",
    "#         raw_path = time_data['ImagePath'].values[0]\n",
    "#         mask_path = time_data['MaskPath'].values[0]\n",
    "#         classification_path = time_data['ClassificationPath'].values[0]\n",
    "\n",
    "#         raw_stack = read_tiff_file(raw_path, channels_to_keep = [1])\n",
    "#         mask_stack = read_tiff_file(mask_path)\n",
    "#         classification_df = pd.read_csv(classification_path)\n",
    "\n",
    "#         nuclei_stats_df = measure_stack_nuclear_stats(raw_stack, mask_stack)\n",
    "#         nuclei_stats_df = nuclei_stats_df.merge(classification_df, on=['Plane', 'Label'], how='left')\n",
    "\n",
    "#         output_path = os.path.join(output_dir, os.path.basename(raw_path).replace('.ome.tiff', '.csv'))\n",
    "#         nuclei_stats_df.to_csv(output_path, index=False)\n",
    "\n",
    "# parallelize time loop with joblib\n",
    "\n",
    "def process_time(time, point_data):\n",
    "    print(f\"Processing time {time}\")\n",
    "    time_data = point_data[point_data['Time'] == time]\n",
    "    raw_path = time_data['ImagePath'].values[0]\n",
    "    mask_path = time_data['MaskPath'].values[0]\n",
    "    classification_path = time_data['ClassificationPath'].values[0]\n",
    "\n",
    "    raw_stack = read_tiff_file(raw_path, channels_to_keep = [1])\n",
    "    mask_stack = read_tiff_file(mask_path)\n",
    "\n",
    "    try:\n",
    "        classification_df = pd.read_csv(classification_path)\n",
    "\n",
    "        nuclei_stats_df = measure_stack_nuclear_stats(raw_stack, mask_stack)\n",
    "        nuclei_stats_df = nuclei_stats_df.merge(classification_df, on=['Plane', 'Label'], how='left')\n",
    "\n",
    "        output_path = os.path.join(output_dir, os.path.basename(raw_path).replace('.ome.tiff', '.csv'))\n",
    "        nuclei_stats_df.to_csv(output_path, index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing time {time}: {e}\")\n",
    "\n",
    "for point in filemap['Point'].unique():\n",
    "    print(f\"Processing point {point}\")\n",
    "    point_data = filemap[filemap['Point'] == point]\n",
    "\n",
    "    Parallel(n_jobs=1)(\n",
    "        delayed(process_time)(time, point_data) for time in point_data['Time'].unique()\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
